{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array = np.asarray  # \u26a0\ufe0f Fixes NumPy 2.0 compatibility issue\n"
      ],
      "metadata": {
        "id": "WJNSUV8HzzVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sympy>=1.13.3"
      ],
      "metadata": {
        "id": "PLvJU-ZZpQgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy\n",
        "import mpmath\n",
        "print(f\"SymPy version: {sympy.__version__}\")\n",
        "print(f\"mpmath version: {mpmath.__version__}\")\n",
        "print(\"Success - packages imported correctly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gLBPCykpUw2",
        "outputId": "7d4c58cb-804c-4887-8bc5-4e5edc25ebcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SymPy version: 1.13.1\n",
            "mpmath version: 1.3.0\n",
            "Success - packages imported correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets nltk scikit-learn pandas\n",
        "print(\"Success\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUkOqm-qpaiC",
        "outputId": "f37ca82c-6237-4ff9-baf5-8d151c53f8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "print(\"\u2713 Both packages working!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy location: {np.__file__}\")\n",
        "print(f\"Pandas location: {pd.__file__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5GHdsSzpeV-",
        "outputId": "4bc3e35c-b12c-451b-af28-18e23d6f94f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2713 Both packages working!\n",
            "NumPy version: 1.26.4\n",
            "Pandas version: 2.2.2\n",
            "NumPy location: /usr/local/lib/python3.11/dist-packages/numpy/__init__.py\n",
            "Pandas location: /usr/local/lib/python3.11/dist-packages/pandas/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "print(\"\u2705 All libraries imported successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l0cg2v9pirY",
        "outputId": "8d380c78-0e25-4157-dcd6-11feee7d4837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array = np.asarray  # patch to fix numpy copy=False error with datasets\n",
        "# Load Tamil training and validation datasets\n",
        "tamil_train = pd.read_csv(\"tamil_offensive_speech_train.csv\")[[\"comment\", \"label\"]]\n",
        "tamil_val = pd.read_csv(\"tamil_offensive_speech_val.csv\")[[\"comment\", \"label\"]]\n",
        "\n",
        "# Rename 'comment' to 'text' (standardized)\n",
        "tamil_train = tamil_train.rename(columns={\"comment\": \"text\"})\n",
        "tamil_val = tamil_val.rename(columns={\"comment\": \"text\"})\n",
        "\n",
        "# Check data shape and first few rows\n",
        "print(f\"Train shape: {tamil_train.shape}\")\n",
        "print(f\"Validation shape: {tamil_val.shape}\")\n",
        "tamil_train.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "TPTbV21ppmyq",
        "outputId": "80e4506c-aa24-449b-8384-c69b28dc93f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (27875, 2)\n",
            "Validation shape: (6969, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0                  omg that bgm make me goosebumb...      0\n",
              "1         neraya neraya neraya neraya neraya neraya.      0\n",
              "2  thalaivar mersal look .semma massss thalaiva ....      0\n",
              "3  paaaa... repeat mode.... adra adra adraaaaa......      0\n",
              "4  epaa ena panaporam... sweet sapade poram... aw...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-daa46be3-60b6-40df-8ea3-ffd2ec61e531\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>omg that bgm make me goosebumb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neraya neraya neraya neraya neraya neraya.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thalaivar mersal look .semma massss thalaiva ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paaaa... repeat mode.... adra adra adraaaaa......</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>epaa ena panaporam... sweet sapade poram... aw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-daa46be3-60b6-40df-8ea3-ffd2ec61e531')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-daa46be3-60b6-40df-8ea3-ffd2ec61e531 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-daa46be3-60b6-40df-8ea3-ffd2ec61e531');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2dada517-d853-4a2b-ab52-e1c06f224dcb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2dada517-d853-4a2b-ab52-e1c06f224dcb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2dada517-d853-4a2b-ab52-e1c06f224dcb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tamil_train",
              "summary": "{\n  \"name\": \"tamil_train\",\n  \"rows\": 27875,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27661,\n        \"samples\": [\n          \"thalapathy 64 ku wait pandravan like adi .....\",\n          \"aeutha ealutu. 2 main rathnam. is. come. back. aravitswami. caratala. thala. acting. panirutha. semmaya. eruthrukum. ar musc\",\n          \"ntk naam tamilar katchi \\u0ba8\\u0bbe\\u0bae\\u0bcd \\u0ba4\\u0bae\\u0bbf\\u0bb4\\u0bb0\\u0bcd \\u0b95\\u0b9f\\u0bcd\\u0b9a\\u0bbf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.strip()               # Remove leading/trailing spaces\n",
        "    text = text.lower()               # Lowercase all text\n",
        "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces/newlines with single space\n",
        "    # Optional: Remove special characters except Tamil letters, numbers and basic punctuation\n",
        "    # text = re.sub(r\"[^a-zA-Z0-9\u0b85\u0b86\u0b87\u0b88\u0b89\u0b8a\u0b8e\u0b8f\u0b90\u0b92\u0b93\u0b94\u0b95\u0b99\u0b9a\u0b9e\u0b9f\u0ba3\u0ba4\u0ba8\u0baa\u0bae\u0baf\u0bb0\u0bb2\u0bb5\u0bb7\u0bb8\u0bb9\u0bbe\u0bbf\u0bc0\u0bc1\u0bc2\u0bc6\u0bc7\u0bc8\u0bca\u0bcb\u0bcc\u0bcd.,!?]\", \" \", text)\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to train and val data\n",
        "tamil_train['text'] = tamil_train['text'].apply(clean_text)\n",
        "tamil_val['text'] = tamil_val['text'].apply(clean_text)\n",
        "\n",
        "# Remove empty or whitespace-only rows after cleaning\n",
        "tamil_train = tamil_train[tamil_train['text'].str.strip() != \"\"]\n",
        "tamil_val = tamil_val[tamil_val['text'].str.strip() != \"\"]\n",
        "\n",
        "# Reset index after cleaning\n",
        "tamil_train = tamil_train.reset_index(drop=True)\n",
        "tamil_val = tamil_val.reset_index(drop=True)\n",
        "\n",
        "print(f\"Cleaned train shape: {tamil_train.shape}\")\n",
        "print(f\"Cleaned val shape: {tamil_val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTlv9j_Gpn97",
        "outputId": "2437acb3-4112-4e59-d710-d4391a077882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned train shape: (27870, 2)\n",
            "Cleaned val shape: (6969, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tamil_train['label'].dtype)  # Should output: int64 or int32\n",
        "print(tamil_val['label'].dtype)    # Should output: int64 or int32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzVJ2DcipsT_",
        "outputId": "a32a07e4-8c5d-479e-be4c-ad13928280d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n",
            "int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "# Convert pandas DataFrame to Huggingface Dataset first\n",
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_pandas(tamil_train)\n",
        "val_dataset = Dataset.from_pandas(tamil_val)\n",
        "\n",
        "# Apply tokenization (batched=True for faster processing)\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set the format for PyTorch tensors (required for training)\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(\"Tokenization done!\")\n",
        "# Temporarily disable the tensor format to access raw data safely\n",
        "train_dataset.set_format(type=None)\n",
        "\n",
        "# Now you can safely access the first example as a dict with numpy arrays or lists\n",
        "example = train_dataset[0]\n",
        "print({k: type(v) for k, v in example.items()})\n",
        "print(example)  # See full example if you want\n",
        "\n",
        "# After inspection, set the format back for training\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "84a29e3b54c14a4ba5229e0301928333",
            "ab43d9a5394947e786c2a9e6e38f2ee2",
            "6bc26ba3536747ab98c335bb9e6bbd8b",
            "0c693e1d3f9342349842e627c7924d5b",
            "38e6331918cc49a0834d8a54508558b4",
            "1bdf60c31eff49dfb1260ae88d67afc0",
            "8e7f82c040c44f2985d36b913b2c003b",
            "5f355ec36d1245159204f7d08682573f",
            "f74912a3425e47feae83f0862200a477",
            "60d0cfbfb95d4d25aa98aab53333f8f4",
            "06723903203e4799a483b8eae73f0eeb",
            "e1e2dfa422724cb6a395f186ed335ba4",
            "a24b235862e04482843fad1a6250b61c",
            "28f91dae321b48c6bfb61904d2fec260",
            "03e49754b1f045df89160c7e718058ad",
            "33fe52de92d14899950fa2e5dd9d0108",
            "54eddf23c462447ba7089b02e7252a47",
            "93b988d0ecf849dd942321647d4d175f",
            "09117620bd6446548a49327c295e7c76",
            "ba6635e84f044d76b2575a01143ca7ad",
            "2aff0d5e365b4797b207ea48c174047d",
            "72f8a2ce986d43bbb08d5197687482d1"
          ]
        },
        "id": "ZmrwGQYTpz_q",
        "outputId": "b366bd7c-0c69-4fd4-e735-0f705979e625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/27870 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84a29e3b54c14a4ba5229e0301928333"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6969 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1e2dfa422724cb6a395f186ed335ba4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization done!\n",
            "{'text': <class 'str'>, 'label': <class 'int'>, 'input_ids': <class 'list'>, 'attention_mask': <class 'list'>}\n",
            "{'text': 'omg that bgm make me goosebumb...', 'label': 0, 'input_ids': [0, 171, 177, 450, 6, 11821, 39, 3249, 163, 738, 8364, 978, 6492, 27, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Number of classes (labels)\n",
        "num_labels = 2  # since your labels are already integers 0 or 1\n",
        "\n",
        "# Load the pretrained XLM-RoBERTa model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=num_labels)\n",
        "\n",
        "print(\"Model loaded with\", num_labels, \"labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toXEIWl-p1s2",
        "outputId": "18e393d3-9947-4318-e94c-2e3eb9bc9ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded with 2 labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary', zero_division=0)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ],
      "metadata": {
        "id": "OA8BANBEp5Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"TrainingArguments module:\", TrainingArguments.__module__)\n",
        "print(\"Transformers installed at:\", transformers.__file__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_53E67-quTWz",
        "outputId": "6c61829c-4a48-458d-febf-5a3ba651da50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.52.4\n",
            "TrainingArguments module: transformers.training_args\n",
            "Transformers installed at: /usr/local/lib/python3.11/dist-packages/transformers/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers\n",
        "!pip list | grep transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23BbeKncuhPV",
        "outputId": "1d7db442-d106-447f-ed23-75f8885d225c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.52.4\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers\n",
            "sentence-transformers                 4.1.0\n",
            "transformers                          4.52.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers==4.52.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GP3UCTtutlk",
        "outputId": "d60c3bd1-bfa8-4693-f9a6-9d7760c690a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.52.4 in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbJQNvrovye7",
        "outputId": "541fc670-efb8-4693-ab54-e0c36354d812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.52.4\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "import numpy as np\n",
        "np.array = np.asarray  # patch to fix numpy copy=False error with datasets\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load CSV files\n",
        "tamil_train = pd.read_csv(\"tamil_offensive_speech_train.csv\")\n",
        "tamil_val = pd.read_csv(\"tamil_offensive_speech_val.csv\")\n",
        "\n",
        "# Replace NaN or None with empty string or drop rows\n",
        "tamil_train['comment'] = tamil_train['comment'].fillna(\"\").astype(str)\n",
        "tamil_val['comment'] = tamil_val['comment'].fillna(\"\").astype(str)\n",
        "tamil_train = tamil_train.rename(columns={\"comment\": \"text\"})\n",
        "tamil_val = tamil_val.rename(columns={\"comment\": \"text\"})\n",
        "\n",
        "\n",
        "# Convert to HuggingFace Datasets\n",
        "train_dataset = Dataset.from_pandas(tamil_train)\n",
        "val_dataset = Dataset.from_pandas(tamil_val)\n",
        "\n",
        "model_name = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # examples[\"text\"] should be a list of strings if batched=True,\n",
        "    # or a single string if batched=False\n",
        "    # So just pass it directly\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],  # list or str both work for tokenizer\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "            )\n",
        "\n",
        "# Tokenize datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Rename label column to labels\n",
        "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
        "val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    return {\"f1\": f1}\n",
        "\n",
        "# Training arguments - keep batch size small to speed up training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model_checkpoints\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "trainer.train()\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", results)\n",
        "\n",
        "# Save model and tokenizer\n",
        "trainer.save_model(\"./saved_model\")\n",
        "tokenizer.save_pretrained(\"./saved_model\")\n",
        "print(\"Model and tokenizer saved in './saved_model'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "ce33c40c082145a78c37e43850775a02",
            "98077bf6590e4c9281c9d1cfc62455cd",
            "d6f50d54b9054671819a9ba818916c46",
            "0ee047ffa57440bb8a148eb912541c8a",
            "f7f33dea226d4bf8aaf4618c6bedde65",
            "5d375f2a10474e848539e6999e4ca3f2",
            "85f8ab4ab1094f4f92329441a6f98555",
            "ea5a6fe318b94d398f766b99408e8a2c",
            "1d2d4ad761b6452ebe3a4cde988c163b",
            "fc44fceef85c42dfb84c3e8d00d5c236",
            "29f6fc4e716b4814b37b0008b4351f19",
            "0ea17693aa7c4432a34b284e3d461b21",
            "878dc9e2df26474696ffe6dca805778e",
            "4797b56d384d4c8e80a20516a2ac4a6a",
            "6935911466084f8d80ee5cb96ed463ca",
            "5ab6cc2e8cbc4b36aae2585bdc432fe9",
            "9633b6fa0eb140e18626147452935c4d",
            "9737c96225694369ac6d277caeec8ca8",
            "a184a2a4f0fe4e3ebaab0d8a105f21b5",
            "98467fc82306463d8c3a00307d097a6b",
            "e13a613b5d234759a831b4bc01cd7617",
            "bd38b64a5ab4486baa8ba81ad9033ef7"
          ]
        },
        "id": "-kKdItZPqJBV",
        "outputId": "fcf39839-4199-4767-b087-a44472eec1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/27875 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce33c40c082145a78c37e43850775a02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6969 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ea17693aa7c4432a34b284e3d461b21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-2786844690>:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmathumethaseenivasagan\u001b[0m (\u001b[33mmathumethaseenivasagan-panimalar-engineering-college\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250614_051202-aq54fi5a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mathumethaseenivasagan-panimalar-engineering-college/huggingface/runs/aq54fi5a' target=\"_blank\">./model_checkpoints</a></strong> to <a href='https://wandb.ai/mathumethaseenivasagan-panimalar-engineering-college/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mathumethaseenivasagan-panimalar-engineering-college/huggingface' target=\"_blank\">https://wandb.ai/mathumethaseenivasagan-panimalar-engineering-college/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mathumethaseenivasagan-panimalar-engineering-college/huggingface/runs/aq54fi5a' target=\"_blank\">https://wandb.ai/mathumethaseenivasagan-panimalar-engineering-college/huggingface/runs/aq54fi5a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6970' max='6970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6970/6970 34:24, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.464500</td>\n",
              "      <td>0.401100</td>\n",
              "      <td>0.807253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.326900</td>\n",
              "      <td>0.394778</td>\n",
              "      <td>0.829011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='872' max='872' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [872/872 00:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 0.3947780132293701, 'eval_f1': 0.8290107170325807, 'eval_runtime': 47.1609, 'eval_samples_per_second': 147.771, 'eval_steps_per_second': 18.49, 'epoch': 2.0}\n",
            "Model and tokenizer saved in './saved_model'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib seaborn scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MlHOuMj_x2d",
        "outputId": "6e125e58-b047-416e-9c13-d2dd166e18e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "predictions = trainer.predict(val_dataset)\n",
        "y_true = predictions.label_ids\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "labels = ['non-hate', 'hate']\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"           Predicted\")\n",
        "print(f\"Actual  {labels[0]:>8} {labels[1]:>8}\")\n",
        "for i, label in enumerate(labels):\n",
        "    print(f\"{label:>6}  {cm[i,0]:8d} {cm[i,1]:8d}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "SbIf1IUQEVm4",
        "outputId": "94a5099a-fb1e-49a4-be2c-10d72803fc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "           Predicted\n",
            "Actual  non-hate     hate\n",
            "non-hate      4825      460\n",
            "  hate       700      984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your confusion matrix results\n",
        "tn, fp, fn, tp = 4825, 460, 700, 984\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"     HATE SPEECH DETECTION MODEL - PERFORMANCE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"                    PREDICTED\")\n",
        "print(\"                non-hate    hate    Total\")\n",
        "print(\"ACTUAL non-hate    {:4d}     {:4d}     {:4d}\".format(tn, fp, tn+fp))\n",
        "print(\"       hate        {:4d}     {:4d}     {:4d}\".format(fn, tp, fn+tp))\n",
        "print(\"       Total       {:4d}     {:4d}     {:4d}\".format(tn+fn, fp+tp, tn+fp+fn+tp))\n",
        "print()\n",
        "\n",
        "# Calculate basic metrics\n",
        "total_samples = tn + fp + fn + tp\n",
        "accuracy = (tp + tn) / total_samples\n",
        "error_rate = (fp + fn) / total_samples\n",
        "\n",
        "print(\"OVERALL PERFORMANCE:\")\n",
        "print(f\"Total Samples: {total_samples:,}\")\n",
        "print(f\"Accuracy: {accuracy:.4f} ({tp+tn:,}/{total_samples:,}) - {accuracy*100:.2f}%\")\n",
        "print(f\"Error Rate: {error_rate:.4f} ({fp+fn:,}/{total_samples:,}) - {error_rate*100:.2f}%\")\n",
        "print()\n",
        "\n",
        "# Per-class metrics\n",
        "# Non-hate class\n",
        "precision_non_hate = tn / (tn + fn)\n",
        "recall_non_hate = tn / (tn + fp)\n",
        "f1_non_hate = 2 * (precision_non_hate * recall_non_hate) / (precision_non_hate + recall_non_hate)\n",
        "\n",
        "# Hate class\n",
        "precision_hate = tp / (tp + fp)\n",
        "recall_hate = tp / (tp + fn)\n",
        "f1_hate = 2 * (precision_hate * recall_hate) / (precision_hate + recall_hate)\n",
        "\n",
        "print(\"DETAILED METRICS BY CLASS:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"NON-HATE CLASS:\")\n",
        "print(f\"  Precision: {precision_non_hate:.4f} - Of all predicted non-hate, {precision_non_hate*100:.1f}% were correct\")\n",
        "print(f\"  Recall:    {recall_non_hate:.4f} - Of all actual non-hate, {recall_non_hate*100:.1f}% were caught\")\n",
        "print(f\"  F1-Score:  {f1_non_hate:.4f}\")\n",
        "print(f\"  Support:   {tn + fp:,} samples\")\n",
        "print()\n",
        "\n",
        "print(\"HATE SPEECH CLASS:\")\n",
        "print(f\"  Precision: {precision_hate:.4f} - Of all predicted hate, {precision_hate*100:.1f}% were correct\")\n",
        "print(f\"  Recall:    {recall_hate:.4f} - Of all actual hate, {recall_hate*100:.1f}% were caught\")\n",
        "print(f\"  F1-Score:  {f1_hate:.4f}\")\n",
        "print(f\"  Support:   {tp + fn:,} samples\")\n",
        "print()\n",
        "\n",
        "# Error analysis\n",
        "fpr = fp / (fp + tn)  # False Positive Rate\n",
        "fnr = fn / (fn + tp)  # False Negative Rate\n",
        "\n",
        "print(\"ERROR BREAKDOWN:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"True Positives (TP):  {tp:,} - Correctly identified hate speech\")\n",
        "print(f\"True Negatives (TN):  {tn:,} - Correctly identified non-hate content\")\n",
        "print(f\"False Positives (FP): {fp:,} - Non-hate content flagged as hate\")\n",
        "print(f\"False Negatives (FN): {fn:,} - Hate speech that was missed\")\n",
        "print()\n",
        "print(f\"False Positive Rate: {fpr:.4f} ({fpr*100:.2f}%)\")\n",
        "print(f\"  \u2192 {fp:,} out of {fp+tn:,} non-hate posts were incorrectly flagged\")\n",
        "print(f\"False Negative Rate: {fnr:.4f} ({fnr*100:.2f}%)\")\n",
        "print(f\"  \u2192 {fn:,} out of {fn+tp:,} hate speech posts were missed\")\n",
        "print()\n",
        "\n",
        "# Balanced metrics\n",
        "macro_precision = (precision_non_hate + precision_hate) / 2\n",
        "macro_recall = (recall_non_hate + recall_hate) / 2\n",
        "macro_f1 = (f1_non_hate + f1_hate) / 2\n",
        "\n",
        "weighted_precision = (precision_non_hate * (tn+fp) + precision_hate * (tp+fn)) / total_samples\n",
        "weighted_recall = (recall_non_hate * (tn+fp) + recall_hate * (tp+fn)) / total_samples\n",
        "weighted_f1 = (f1_non_hate * (tn+fp) + f1_hate * (tp+fn)) / total_samples\n",
        "\n",
        "print(\"AVERAGE METRICS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Macro Average:\")\n",
        "print(f\"  Precision: {macro_precision:.4f}\")\n",
        "print(f\"  Recall:    {macro_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {macro_f1:.4f}\")\n",
        "print()\n",
        "print(f\"Weighted Average:\")\n",
        "print(f\"  Precision: {weighted_precision:.4f}\")\n",
        "print(f\"  Recall:    {weighted_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {weighted_f1:.4f}\")\n",
        "print()\n",
        "\n",
        "# Class distribution analysis\n",
        "hate_percentage = (tp + fn) / total_samples * 100\n",
        "non_hate_percentage = (tn + fp) / total_samples * 100\n",
        "\n",
        "print(\"DATASET COMPOSITION:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Non-hate samples: {tn+fp:,} ({non_hate_percentage:.1f}%)\")\n",
        "print(f\"Hate samples:     {tp+fn:,} ({hate_percentage:.1f}%)\")\n",
        "print(f\"Class imbalance ratio: {(tn+fp)/(tp+fn):.1f}:1 (non-hate:hate)\")\n",
        "print()\n",
        "\n",
        "# Performance interpretation\n",
        "print(\"MODEL PERFORMANCE ASSESSMENT:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Overall assessment\n",
        "if accuracy > 0.85:\n",
        "    accuracy_assessment = \"Excellent\"\n",
        "elif accuracy > 0.75:\n",
        "    accuracy_assessment = \"Good\"\n",
        "elif accuracy > 0.65:\n",
        "    accuracy_assessment = \"Fair\"\n",
        "else:\n",
        "    accuracy_assessment = \"Poor\"\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy_assessment} ({accuracy*100:.1f}%)\")\n",
        "\n",
        "# Hate detection specific\n",
        "if precision_hate > 0.8:\n",
        "    precision_assessment = \"High precision - Low false positive rate\"\n",
        "elif precision_hate > 0.6:\n",
        "    precision_assessment = \"Moderate precision - Some false positives\"\n",
        "else:\n",
        "    precision_assessment = \"Low precision - Many false positives\"\n",
        "\n",
        "if recall_hate > 0.8:\n",
        "    recall_assessment = \"High recall - Catches most hate speech\"\n",
        "elif recall_hate > 0.6:\n",
        "    recall_assessment = \"Moderate recall - Misses some hate speech\"\n",
        "else:\n",
        "    recall_assessment = \"Low recall - Misses significant hate speech\"\n",
        "\n",
        "print(f\"Hate Detection Precision: {precision_assessment} ({precision_hate:.3f})\")\n",
        "print(f\"Hate Detection Recall: {recall_assessment} ({recall_hate:.3f})\")\n",
        "print()\n",
        "\n",
        "# Recommendations\n",
        "print(\"RECOMMENDATIONS:\")\n",
        "print(\"-\" * 50)\n",
        "if fnr > 0.3:\n",
        "    print(\"\u26a0\ufe0f  High False Negative Rate - Consider:\")\n",
        "    print(\"   \u2022 Adjusting classification threshold\")\n",
        "    print(\"   \u2022 Adding more hate speech examples to training\")\n",
        "    print(\"   \u2022 Using class weights to penalize false negatives more\")\n",
        "\n",
        "if fpr > 0.1:\n",
        "    print(\"\u26a0\ufe0f  High False Positive Rate - Consider:\")\n",
        "    print(\"   \u2022 Improving model's understanding of context\")\n",
        "    print(\"   \u2022 Adding more diverse non-hate examples\")\n",
        "    print(\"   \u2022 Fine-tuning to reduce over-sensitivity\")\n",
        "\n",
        "if f1_hate < 0.7:\n",
        "    print(\"\u26a0\ufe0f  Low F1-Score for hate detection - Consider:\")\n",
        "    print(\"   \u2022 Balancing precision and recall\")\n",
        "    print(\"   \u2022 More sophisticated model architecture\")\n",
        "    print(\"   \u2022 Better feature engineering\")\n",
        "\n",
        "print(f\"\\n\u2705 Model successfully identifies {recall_hate*100:.1f}% of hate speech\")\n",
        "print(f\"\u2705 {precision_hate*100:.1f}% of hate predictions are correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq2bcDPZE08h",
        "outputId": "00878cb3-f0c5-4f84-9d85-671b870af2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "     HATE SPEECH DETECTION MODEL - PERFORMANCE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "                    PREDICTED\n",
            "                non-hate    hate    Total\n",
            "ACTUAL non-hate    4825      460     5285\n",
            "       hate         700      984     1684\n",
            "       Total       5525     1444     6969\n",
            "\n",
            "OVERALL PERFORMANCE:\n",
            "Total Samples: 6,969\n",
            "Accuracy: 0.8335 (5,809/6,969) - 83.35%\n",
            "Error Rate: 0.1665 (1,160/6,969) - 16.65%\n",
            "\n",
            "DETAILED METRICS BY CLASS:\n",
            "--------------------------------------------------\n",
            "NON-HATE CLASS:\n",
            "  Precision: 0.8733 - Of all predicted non-hate, 87.3% were correct\n",
            "  Recall:    0.9130 - Of all actual non-hate, 91.3% were caught\n",
            "  F1-Score:  0.8927\n",
            "  Support:   5,285 samples\n",
            "\n",
            "HATE SPEECH CLASS:\n",
            "  Precision: 0.6814 - Of all predicted hate, 68.1% were correct\n",
            "  Recall:    0.5843 - Of all actual hate, 58.4% were caught\n",
            "  F1-Score:  0.6292\n",
            "  Support:   1,684 samples\n",
            "\n",
            "ERROR BREAKDOWN:\n",
            "--------------------------------------------------\n",
            "True Positives (TP):  984 - Correctly identified hate speech\n",
            "True Negatives (TN):  4,825 - Correctly identified non-hate content\n",
            "False Positives (FP): 460 - Non-hate content flagged as hate\n",
            "False Negatives (FN): 700 - Hate speech that was missed\n",
            "\n",
            "False Positive Rate: 0.0870 (8.70%)\n",
            "  \u2192 460 out of 5,285 non-hate posts were incorrectly flagged\n",
            "False Negative Rate: 0.4157 (41.57%)\n",
            "  \u2192 700 out of 1,684 hate speech posts were missed\n",
            "\n",
            "AVERAGE METRICS:\n",
            "--------------------------------------------------\n",
            "Macro Average:\n",
            "  Precision: 0.7774\n",
            "  Recall:    0.7486\n",
            "  F1-Score:  0.7609\n",
            "\n",
            "Weighted Average:\n",
            "  Precision: 0.8269\n",
            "  Recall:    0.8335\n",
            "  F1-Score:  0.8290\n",
            "\n",
            "DATASET COMPOSITION:\n",
            "--------------------------------------------------\n",
            "Non-hate samples: 5,285 (75.8%)\n",
            "Hate samples:     1,684 (24.2%)\n",
            "Class imbalance ratio: 3.1:1 (non-hate:hate)\n",
            "\n",
            "MODEL PERFORMANCE ASSESSMENT:\n",
            "--------------------------------------------------\n",
            "Overall Accuracy: Good (83.4%)\n",
            "Hate Detection Precision: Moderate precision - Some false positives (0.681)\n",
            "Hate Detection Recall: Low recall - Misses significant hate speech (0.584)\n",
            "\n",
            "RECOMMENDATIONS:\n",
            "--------------------------------------------------\n",
            "\u26a0\ufe0f  High False Negative Rate - Consider:\n",
            "   \u2022 Adjusting classification threshold\n",
            "   \u2022 Adding more hate speech examples to training\n",
            "   \u2022 Using class weights to penalize false negatives more\n",
            "\u26a0\ufe0f  Low F1-Score for hate detection - Consider:\n",
            "   \u2022 Balancing precision and recall\n",
            "   \u2022 More sophisticated model architecture\n",
            "   \u2022 Better feature engineering\n",
            "\n",
            "\u2705 Model successfully identifies 58.4% of hate speech\n",
            "\u2705 68.1% of hate predictions are correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7Ez0EJJGywY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}